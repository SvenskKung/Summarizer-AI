# Summarizer-AI
Building AI Course Project
## Summary
I plan to build an AI that summarizes various bodies of text, with an explicit focus on research papers. The goal of this AI is to help make it easier to understand and keep up with the massive influx of research papers that are currently being released daily. Through human means it would simply be impossible to do so. It's my hope that this tool will efficiently provide a brief but informative summary of the research paper that will lead to a deeper understanding of the paper's contents.
## Background
The AI will be solving the problem of the sheer tide of papers coming out being impossible to read through. Hopefully it will allow us to recognize more information from these papers and stay on top of cutting edge research. The problem is becoming more frequent as of late. The number of research papers is increasing rapidly, especially in the field of AI. It’s currently impossible to stay informed about everything that’s going on. That said, my personal motivation is to try to do my part to lower the overwhelming sensation that is being caused by this. Currently the world is changing too fast and the only way that we can prepare is if we stay on top of what’s going on. 
## Data and AI Techniques
This model will depend on a massive corpus of text, with the primary focus being on learning how to build connections between words and ideas in language. This data will either be the result of pre-curated data sets that are specialized for models such as OpenAI’s GPT or Common Crawls. The techniques that will be essential will be using a Neural Network, and if complexity is needed, stacking some Transformers on top of it. I will also need to focus on Natural Language Processing. As the model gets better at processing and understanding language, it will eventually utilize an API that will allow it to either automatically access open source research papers, or allow users to paste a URL or upload a file that it will then summarize. I am not currently very skilled in programming, as I have only been programming for less than 2 months, but I will return to this in the near future to flesh out some of the code for the model as my knowledge increases.
## How is it used
The model will be used to make researching information and keeping up with recent research papers a lot easier. Hopefully it will be simplifying the process for absolutely anyone who wishes to use it. Anyone who wishes to stay up to date on recent scientific developments will be able to benefit from the model.
## Challenges
The model will have some limitations unfortunately. For example, it will not be given automatic access to papers that are not openly available and may make mistakes when summarizing data. It will also not stem the tide of research papers being released daily but it should make it easier to stay up to date on them. The project will help simplify gaps in domain knowledge but self-education on the topics will likely still be required.
## What next
The project could eventually grow into a personal assistant connected to standard web browsers that can summarize whatever is on the screen if the user so chooses. It can also get to the point of helping people develop, outline, or write research papers as well, since it will specialize in understanding them.
## Acknowledgements
Currently there is no data being used in this project, but this will change as it develops. I will be adding acknowledgements over time as required. I can definitely express here my appreciation for the AI community in general however. It is simply awe-inspiring to me how much effort people put into this domain, simply for the sake of others. I hope that I too can do my part. You guys inspire me. I do this so that I may be helpful and perhaps a source of inspiration myself.
